{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP5J7CIbCsGl8QPojDiph9q"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"f-aUY6nq_2Tw","executionInfo":{"status":"ok","timestamp":1762909407965,"user_tz":-540,"elapsed":7047,"user":{"displayName":"good_neighbour","userId":"07152320100777426345"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"f83d7e50-dd43-4fb2-9efe-48e50ba06414"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{},"execution_count":1}],"source":["# 라이브러리 설치\n","import os\n","os.system(\"pip -q install --upgrade transformers\")"]},{"cell_type":"code","source":["# 라이브러리 임포트\n","from sklearn.model_selection import train_test_split\n","from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer, pipeline\n","from torch.utils.data import Dataset\n","import pandas as pd"],"metadata":{"id":"e4Nox4C4127L","executionInfo":{"status":"ok","timestamp":1762909477992,"user_tz":-540,"elapsed":70025,"user":{"displayName":"good_neighbour","userId":"07152320100777426345"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# 스타일맵\n","StyleMap = {\n","    'formal': '문어체',\n","    'informal': '구어체',\n","    'android': '안드로이드',\n","    'azae': '아재',\n","    'chat': '채팅',\n","    'choding': '초등학생',\n","    'emoticon': '이모티콘',\n","    'enfp': 'enfp',\n","    'gentle': '신사',\n","    'halbae': '할아버지',\n","    'halmae': '할머니',\n","    'joongding': '중학생',\n","    'king': '왕',\n","    'naruto': '나루토',\n","    'seonbi': '선비',\n","    'sosim': '소심한',\n","    'translator': '번역기'\n","}"],"metadata":{"id":"ns-mOJdqvLJu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 부모 클래스\n","class ModelBase:\n","  \"\"\"\n","  부모 클래스.\n","  사용자 측에서 생성할 것을 권장하지 않음.\n","  \"\"\"\n","  def __init__(self):\n","    self._styleMap = StyleMap\n","\n","  def Help():\n","    pass"],"metadata":{"id":"pmBDhrFJyLEL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 모델 학습 클래스\n","class TrainProcess(ModelBase):\n","  \"\"\"\n","  모델 학습 클래스\n","  \"\"\"\n","  def __init__(\n","      self,\n","      model_name: str = \"gogamza/kobart-base-v2\"\n","  ):\n","    super().__init__()\n","    self.__trainDF = None\n","    self.__testDF = None\n","    self.__trainDS = None\n","    self.__testDS = None\n","    self.__tokenizer = AutoTokenizer.from_pretrained(model_name)\n","    self.__model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n","    self.__DataCollator = DataCollatorForSeq2Seq(tokenizer = self.__tokenizer, model = self.__model)\n","    self.__trainer = None\n","\n","\n","\n","\n","  def SplitTrainTestData(\n","      self,\n","      dataset_path: str,\n","      nan_allow: int = 2,\n","      test_size: float = 0.1,\n","      random_state: int = 1945,\n","      show_result: bool = True\n","  ):\n","    \"\"\"\n","    데이터 프레임을 학습/테스트 데이터로 분리\n","\n","    dataset_path : 데이터셋 경로\n","    nan_allow : 한 행의 결측치 허용 개수\n","    test_size : 테스트 데이터 크기\n","    random_state : 랜덤 시드\n","    show_result : 결과 출력\n","    \"\"\"\n","    # 데이터 불러오기\n","    data = pd.read_csv(dataset_path, sep = \"\\t\")\n","\n","    # 결측치 허용범위를 초과하는 행은 제거\n","    data = data[data.notna().sum(axis=1) >= nan_allow]\n","\n","    # 학습, 테스트 데이터 분리\n","    self.__trainDF, self.__testDF = train_test_split(\n","        data,\n","        test_size = test_size,\n","        random_state = random_state\n","    )\n","\n","    # 결과 출력\n","    if show_result:\n","      print(f\"학습 데이터: {self.__trainDF.shape}, 테스트 데이터: {self.__testDF.shape}\\n\")\n","\n","    # 자기 자신 객체를 반환\n","    return self\n","\n","\n","\n","\n","  def SetDatasets(\n","      self,\n","      max_length: int = 64,\n","      truncation: bool = True,\n","      clear_dataframe_after_dataset: bool = True,\n","      show_result: bool = True\n","  ):\n","    \"\"\"\n","    학습을 위한 데이터셋 설정\n","\n","    max_length : 최대 토큰 길이\n","    truncation : 최대 길이 초과 시 잘라내기\n","    clear_dataframe_after_dataset : 데이터셋 생성 후 데이터 프레임 참조 해제\n","    show_result : 결과 출력\n","    \"\"\"\n","    # 데이터셋 생성\n","    self.__trainDS = self.TextStyleDataset(\n","        self.__trainDF,\n","        self.__tokenizer,\n","        max_length,\n","        truncation,\n","        self._styleMap\n","    )\n","    self.__testDS = self.TextStyleDataset(\n","        self.__testDF,\n","        self.__tokenizer,\n","        max_length,\n","        truncation,\n","        self._styleMap\n","    )\n","\n","    # 불필요한 데이터 프레임 참조 해제\n","    if clear_dataframe_after_dataset:\n","      self.__trainDF = None\n","      self.__testDF = None\n","\n","    # 결과 출력\n","    if show_result:\n","      print(\"학습/테스트 데이터셋 생성.\\n\")\n","\n","    # 자기 자신 객체를 반환\n","    return self\n","\n","\n","\n","\n","  def SetTrainingArguments(\n","      self,\n","      output_dir = \"./data/text-transfer-smilegate-bart-eos/dummy/\",\n","      overwrite_output_dir = True,\n","      num_train_epochs = 24,\n","      per_device_train_batch_size = 16,\n","      per_device_eval_batch_size = 16,\n","      eval_steps = 500,\n","      warmup_steps = 300,\n","      prediction_loss_only = True,\n","      evaluation_strategy = \"steps\",\n","      save_strategy = \"no\",\n","      save_steps = 0,\n","      save_total_limit = 0,\n","      logging_dir = None,\n","      logging_strategy = \"no\",\n","      do_eval = False,\n","      do_predict = False,\n","      load_best_model_at_end = False,\n","      metric_for_best_model = 'eval_loss',\n","      show_result: bool = True\n","  ):\n","    \"\"\"\n","    학습 준비\n","    \"\"\"\n","    # Training Arguments\n","    trainingArgs = Seq2SeqTrainingArguments(\n","        output_dir = output_dir,\n","        overwrite_output_dir = overwrite_output_dir,\n","        num_train_epochs = num_train_epochs,\n","        per_device_train_batch_size = per_device_train_batch_size,\n","        per_device_eval_batch_size = per_device_eval_batch_size,\n","        eval_steps = eval_steps,\n","        warmup_steps = warmup_steps,\n","        prediction_loss_only = prediction_loss_only,\n","        eval_strategy = evaluation_strategy,\n","        save_strategy = save_strategy,\n","        save_steps = save_steps,\n","        save_total_limit = save_total_limit,\n","        logging_dir = logging_dir,\n","        logging_strategy = logging_strategy,\n","        do_eval = do_eval,\n","        do_predict = do_predict,\n","        load_best_model_at_end = load_best_model_at_end,\n","        metric_for_best_model = metric_for_best_model\n","    )\n","\n","    # 결과 출력\n","    if show_result:\n","      print(\"Training Arguments 설정 완료.\")\n","      if output_dir != None:\n","        print(\" 모델 학습 시 저장 경로: \", output_dir)\n","\n","    # Trainer\n","    self.__trainer = Seq2SeqTrainer(\n","        model = self.__model,\n","        args = trainingArgs,\n","        data_collator = self.__DataCollator,\n","        train_dataset = self.__trainDS,\n","        eval_dataset = self.__testDS,\n","    )\n","\n","    # 결과 출력\n","    if show_result:\n","      print(\"Trainer 설정 완료\\n\")\n","\n","    # 자기 자신 객체를 반환\n","    return self\n","\n","\n","\n","\n","  def Train(\n","      self,\n","      clear_data_after_training: bool = True,\n","      show_result: bool = True\n","  ):\n","    \"\"\"\n","    모델 학습\n","\n","    clear_data_after_training : 학습 후 사용하지 않는 데이터 참조 해제\n","    show_result : 결과 출력\n","    \"\"\"\n","    # 학습\n","    self.__trainer.train()\n","\n","    # 불필요한 데이터 참조 해제\n","    if clear_data_after_training:\n","      self.ClearData()\n","\n","    # 결과 출력\n","    if show_result:\n","      print(\"학습 완료.\\n\")\n","\n","    # 자기 자신 객체를 반환\n","    return self\n","\n","\n","\n","\n","  def SaveModel(\n","      self,\n","      path: str,\n","      show_result: bool = True\n","  ):\n","    \"\"\"\n","    학습된 모델 저장\n","\n","    path : 저장 경로\n","    show_result : 결과 출력\n","    \"\"\"\n","    if self.__trainer == None:\n","      print(\"SaveModel() 오류. 저장할 모델이 없음.\\n\")\n","    else:\n","      self.__trainer.save_model(path)\n","      if show_result:\n","        print(f\"학습한 모델 저장.\\n저장 경로: {path}\\n\")\n","\n","    # 자기 자신 객체를 반환\n","    return self\n","\n","\n","\n","\n","  def ClearData(self):\n","    \"\"\"\n","    학습된 모델, 스타일맵을 제외한 모든 데이터 참조 해제\n","    \"\"\"\n","    self.__trainDF = None\n","    self.__testDF = None\n","    self.__trainDS = None\n","    self.__testDS = None\n","    self.__tokenizer = None\n","    self.__model = None\n","    self.__DataCollator = None\n","\n","\n","\n","\n","  def Help():\n","    \"\"\"\n","    도움말 출력\n","    \"\"\"\n","    print(\n","\"\"\"\n","모델 생성 순서\n","1. SplitTrainTestData : 데이터 프레임을 학습/테스트 데이터로 분리\n","2. SetDatasets : 학습을 위한 데이터셋 설정\n","3. SetTrainingArguments : 학습 준비\n","4. Train : 모델 학습\n","\n","선택 사항\n","SaveModel : 학습된 모델 저장\n","ClearData : 학습된 모델, 스타일맵을 제외한 모든 데이터 참조 해제\n","\n","모든 함수는 자기 자신의 객체를 반환.\n","매개변수에 대해서는 함수 설명 참고.\n","\"\"\"\n","    )\n","\n","\n","\n","\n","  class TextStyleDataset(Dataset):\n","    \"\"\"\n","    학습을 위한 데이터셋 클래스.\n","    사용자 측에서 생성할 것을 권장하지 않음.\n","    \"\"\"\n","    def __init__(\n","        self,\n","        data,\n","        tokenizer,\n","        max_length,\n","        truncation,\n","        style_map\n","    ):\n","      self.__data = data\n","      self.__tokenizer = tokenizer\n","      self.__maxLength = max_length\n","      self.__truncation = truncation\n","      self.__StyleMap = style_map\n","\n","    def __len__(self):\n","      return len(self.__data)\n","\n","    def __getitem__(self, index):\n","      # 무작위 스타일 2개 추출\n","      row = self.__data.iloc[index, :].dropna().sample(2)\n","\n","      # 인코더 텍스트 설정\n","      encoder_text = f\"{self.__StyleMap[row.index[1]]} 말투로 변환:{row[0]}\"\n","\n","      # 디코더 텍스트 설정\n","      decoder_text = f\"{row[1]}{self.__tokenizer.eos_token}\"\n","\n","      # 인코더 설정\n","      model_inputs = self.__tokenizer(\n","          encoder_text,\n","          max_length = self.__maxLength,\n","          truncation = self.__truncation\n","      )\n","\n","      # 디코더 설정\n","      with self.__tokenizer.as_target_tokenizer():\n","        labels = self.__tokenizer(\n","            decoder_text,\n","            max_length = self.__maxLength,\n","            truncation = self.__truncation\n","        )\n","      model_inputs['labels'] = labels['input_ids']\n","\n","      # 불필요한 요소 제거\n","      del model_inputs['token_type_ids']\n","\n","      # 반환\n","      return model_inputs"],"metadata":{"id":"g8dm5omDIWor"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 텍스트 변환 클래스\n","class ModelPipeline(ModelBase):\n","  \"\"\"\n","  텍스트 변환 클래스\n","  \"\"\"\n","  def __init__(\n","      self,\n","      model_name: str = \"gogamza/kobart-base-v2\",\n","      model_path: str = \"./data/text-transfer-smilegate-bart-eos/\"\n","  ):\n","    super().__init__()\n","    self.__pipeline = pipeline(\n","        'text2text-generation',\n","        model = model_path,\n","        tokenizer = model_name\n","    )\n","\n","\n","\n","\n","  def GenerateText(\n","      self,\n","      text: str,\n","      target_style: str,\n","      num_return_sequences: int = 5,\n","      max_new_tokens: int = 256\n","  ):\n","    \"\"\"\n","    스타일 변환\n","    \"\"\"\n","    # 텍스트 생성\n","    out = self.__pipeline(\n","        f\"{self._styleMap[target_style]} 말투로 변환:{text}\",\n","        num_return_sequences = num_return_sequences,\n","        max_new_tokens = max_new_tokens\n","    )\n","\n","    # 반환\n","    return [x['generated_text'] for x in out]\n","\n","\n","\n","\n","  def Help():\n","    \"\"\"\n","    도움말 출력\n","    \"\"\"\n","    print(\n","\"\"\"\n","GenerateText : 텍스트를 입력해서 스타일 변환\n","\"\"\"\n","    )"],"metadata":{"id":"TkRnLP3Exs8y"},"execution_count":null,"outputs":[]}]}