import os
import time
import json
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from webdriver_manager.chrome import ChromeDriverManager

# ==========================================
# âš™ï¸ ì„¤ì •
# ==========================================
TARGET_COUNT = 36000    # ëª©í‘œ ìˆ˜ì§‘ ê°œìˆ˜
SAVE_FILE = "all_urls.json"
TARGET_URL = "https://www.musinsa.com/app/codimap/lists"

# ==========================================
# ğŸš€ URL ìˆ˜ì§‘ê¸° (ì„±ê³µí•œ ë¡œì§ ê·¸ëŒ€ë¡œ)
# ==========================================
def collect_urls_exact_copy():
    print(f"ğŸš€ URL ìˆ˜ì§‘ ì‹œì‘ (ëª©í‘œ: {TARGET_COUNT}ê°œ)")
    
    # 1. ì„¤ì • (ì•„ê¹Œ ì„±ê³µí•œ ì˜µì…˜ ê·¸ëŒ€ë¡œ)
    chrome_options = Options()
    chrome_options.add_experimental_option("detach", True)
    chrome_options.add_argument("--start-maximized")
    chrome_options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36")
    
    service = Service(ChromeDriverManager().install())
    driver = webdriver.Chrome(service=service, options=chrome_options)
    
    # 2. ì´ˆê¸°í™”
    detail_urls = []
    visited_urls = set()
    
    # ì´ì–´í•˜ê¸° ê¸°ëŠ¥ (ê¸°ì¡´ íŒŒì¼ ìˆìœ¼ë©´ ë¡œë“œ)
    if os.path.exists(SAVE_FILE):
        with open(SAVE_FILE, "r", encoding="utf-8") as f:
            try:
                loaded_data = json.load(f)
                detail_urls = loaded_data
                visited_urls = set(loaded_data)
                print(f"ğŸ“‚ ê¸°ì¡´ ë°ì´í„° {len(detail_urls)}ê°œë¥¼ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.")
            except: pass

    driver.get(TARGET_URL)
    time.sleep(3) # ì´ˆê¸° ë¡œë”©

    print("ğŸ“‹ URL ìˆ˜ì§‘ ì¤‘...")
    
    # 3. ë¬´í•œ ë£¨í”„ (ì•„ê¹Œ ì„±ê³µí•œ ë°©ì‹)
    while len(detail_urls) < TARGET_COUNT:
        
        # í™”ë©´ì˜ ëª¨ë“  'a' íƒœê·¸ ì°¾ê¸°
        links = driver.find_elements(By.CSS_SELECTOR, "a")
        
        # ì´ë²ˆ ìŠ¤í¬ë¡¤ì—ì„œ ìƒˆë¡œ ì°¾ì€ ê°œìˆ˜
        new_found_count = 0
        
        for link in links:
            # ëª©í‘œ ë‹¬ì„±í•˜ë©´ ì¦‰ì‹œ ì¢…ë£Œ
            if len(detail_urls) >= TARGET_COUNT:
                break
            
            try:
                href = link.get_attribute("href")
                # ìœ íš¨ì„± ê²€ì‚¬ (codimap/views ë˜ëŠ” /snap/)
                if href and ("codimap/views" in href or "/snap/" in href):
                    # ì¤‘ë³µ í™•ì¸
                    if href not in visited_urls:
                        detail_urls.append(href)
                        visited_urls.add(href)
                        new_found_count += 1
                        
                        # ì§„í–‰ ìƒí™© ì¶œë ¥ (ë„ˆë¬´ ìì£¼ ì°íˆë©´ ì •ì‹ ì—†ìœ¼ë‹ˆ 100ê°œ ë‹¨ìœ„ë‚˜, ìƒˆë¡œ ì°¾ì•˜ì„ ë•Œë§Œ)
                        # print(f"  ğŸ“Œ ë§í¬ í™•ë³´ [{len(detail_urls)}/{TARGET_COUNT}]")
            except:
                continue
        
        print(f"â¬‡ï¸ í˜„ì¬ ìˆ˜ì§‘: {len(detail_urls)}ê°œ (ë°©ê¸ˆ +{new_found_count}ê°œ)")
        
        # ëª©í‘œ ë‹¬ì„± ì²´í¬
        if len(detail_urls) >= TARGET_COUNT:
            break
            
        # 4. ìŠ¤í¬ë¡¤ ë‚´ë¦¬ê¸° (ì•„ê¹Œ ì½”ë“œ ê·¸ëŒ€ë¡œ)
        driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
        time.sleep(2) # ë¡œë”© ëŒ€ê¸°

        # 5. ì¤‘ê°„ ì €ì¥ (ë°ì´í„° ë³´í˜¸ìš©)
        # íŒŒì¼ ì €ì¥ì€ ì•ˆì „ì„ ìœ„í•´ 500ê°œ ì¶”ê°€ë  ë•Œë§ˆë‹¤ ìˆ˜í–‰
        if len(detail_urls) % 500 < 60: 
            with open(SAVE_FILE, "w", encoding="utf-8") as f:
                json.dump(detail_urls, f, ensure_ascii=False, indent=4)
                print("   ğŸ’¾ ì¤‘ê°„ ì €ì¥ ì™„ë£Œ")

    # ìµœì¢… ì €ì¥
    with open(SAVE_FILE, "w", encoding="utf-8") as f:
        json.dump(detail_urls, f, ensure_ascii=False, indent=4)
        
    driver.quit()
    print(f"\nğŸ‰ URL ìˆ˜ì§‘ ë! ì´ {len(detail_urls)}ê°œê°€ '{SAVE_FILE}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    collect_urls_exact_copy()