{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95ac9789-3381-4562-aabd-4c8bbb80d291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\test os\\anaconda3\\envs\\pw312\\lib\\site-packages (2.32.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\test os\\anaconda3\\envs\\pw312\\lib\\site-packages (from requests) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\test os\\anaconda3\\envs\\pw312\\lib\\site-packages (from requests) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\test os\\anaconda3\\envs\\pw312\\lib\\site-packages (from requests) (2.6.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\test os\\anaconda3\\envs\\pw312\\lib\\site-packages (from requests) (2025.11.12)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: tqdm in c:\\users\\test os\\anaconda3\\envs\\pw312\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\test os\\anaconda3\\envs\\pw312\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\test os\\anaconda3\\envs\\pw312\\lib\\site-packages (4.14.3)\n",
      "Requirement already satisfied: lxml in c:\\users\\test os\\anaconda3\\envs\\pw312\\lib\\site-packages (6.0.2)\n",
      "Requirement already satisfied: soupsieve>=1.6.1 in c:\\users\\test os\\anaconda3\\envs\\pw312\\lib\\site-packages (from beautifulsoup4) (2.8)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\test os\\anaconda3\\envs\\pw312\\lib\\site-packages (from beautifulsoup4) (4.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "!pip -q install requests beautifulsoup4 lxml pandas tqdm\n",
    "%pip install requests\n",
    "%pip install tqdm\n",
    "%pip install beautifulsoup4 lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21fa6f19-67d3-4be6-8f57-794c5e78dc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "from urllib.parse import urljoin, urlparse\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "352034ba-46ca-4381-a1f5-fd6c8fbc7f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE = \"https://www.elle.co.kr\"\n",
    "\n",
    "SESSION = requests.Session()\n",
    "SESSION.headers.update({\n",
    "    \"User-Agent\": (\n",
    "        \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "        \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "        \"Chrome/120.0.0.0 Safari/537.36\"\n",
    "    ),\n",
    "    \"Accept-Language\": \"ko-KR,ko;q=0.9,en;q=0.8\",\n",
    "})\n",
    "\n",
    "def polite_sleep(min_s=0.6, max_s=1.3):\n",
    "    time.sleep(random.uniform(min_s, max_s))\n",
    "\n",
    "def get_soup(url, timeout=20):\n",
    "    r = SESSION.get(url, timeout=timeout)\n",
    "    r.raise_for_status()\n",
    "    return BeautifulSoup(r.text, \"lxml\")\n",
    "\n",
    "def clean_text(s: str) -> str:\n",
    "    if not s:\n",
    "        return \"\"\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "   \n",
    "    s = s.replace(\"전체 페이지를 읽으시려면 회원가입 및 로그인을 해주세요!\", \"\").strip()\n",
    "    return s\n",
    "\n",
    "def is_elle_article_url(href: str) -> bool:\n",
    "    # /article/xxxx 형태만 수집\n",
    "    return bool(href) and \"/article/\" in href\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9e02bb8-d066-4782-b362-62dbf862e574",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64,\n",
       " ['https://www.elle.co.kr/article/1878702',\n",
       "  'https://www.elle.co.kr/article/1882445',\n",
       "  'https://www.elle.co.kr/article/1884766',\n",
       "  'https://www.elle.co.kr/article/1885541',\n",
       "  'https://www.elle.co.kr/article/1886775',\n",
       "  'https://www.elle.co.kr/article/1888060',\n",
       "  'https://www.elle.co.kr/article/1889942',\n",
       "  'https://www.elle.co.kr/article/1889950',\n",
       "  'https://www.elle.co.kr/article/1890164',\n",
       "  'https://www.elle.co.kr/article/1890202'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def collect_article_links_from_fashion(\n",
    "    start_url=\"https://www.elle.co.kr/fashion\",\n",
    "    max_pages=5\n",
    "):\n",
    "    \"\"\"\n",
    "    - fashion 섹션 페이지를 돌면서 /article/ 링크를 최대한 수집\n",
    "    - 페이지네이션 구조가 바뀔 수 있어서:\n",
    "      1) 현재 페이지에서 article 링크를 먼저 긁고\n",
    "      2) '다음/더보기' 류 링크를 찾으면 따라가고\n",
    "      3) 못 찾으면 종료\n",
    "    \"\"\"\n",
    "    seen_pages = set()\n",
    "    article_links = set()\n",
    "\n",
    "    next_url = start_url\n",
    "    for page_idx in range(max_pages):\n",
    "        if not next_url or next_url in seen_pages:\n",
    "            break\n",
    "        seen_pages.add(next_url)\n",
    "\n",
    "        soup = get_soup(next_url)\n",
    "       \n",
    "        for a in soup.select(\"a[href]\"):\n",
    "            href = a.get(\"href\")\n",
    "            if not href:\n",
    "                continue\n",
    "            full = urljoin(BASE, href)\n",
    "            if is_elle_article_url(full):\n",
    "               \n",
    "                full = full.split(\"?\")[0].rstrip(\"/\")\n",
    "                article_links.add(full)\n",
    "\n",
    "        \n",
    "        candidates = []\n",
    "\n",
    "        \n",
    "        rel_next = soup.select_one('a[rel=\"next\"][href]')\n",
    "        if rel_next:\n",
    "            candidates.append(urljoin(BASE, rel_next[\"href\"]))\n",
    "\n",
    "        \n",
    "        for a in soup.select(\"a[href]\"):\n",
    "            txt = (a.get_text(\" \", strip=True) or \"\").lower()\n",
    "            if any(k in txt for k in [\"다음\", \"next\", \"more\", \"더보기\"]):\n",
    "                candidates.append(urljoin(BASE, a[\"href\"]))\n",
    "\n",
    "        \n",
    "        for a in soup.select(\"a[href*='page'], a[href*='Page'], a[href*='paging']\"):\n",
    "            candidates.append(urljoin(BASE, a[\"href\"]))\n",
    "\n",
    "        \n",
    "        candidates = [u for u in candidates if \"/fashion\" in u]\n",
    "        candidates = [u.split(\"#\")[0] for u in candidates]\n",
    "\n",
    "        \n",
    "        next_url = None\n",
    "        for u in candidates:\n",
    "            if u not in seen_pages:\n",
    "                next_url = u\n",
    "                break\n",
    "\n",
    "        polite_sleep()\n",
    "\n",
    "    return sorted(article_links)\n",
    "\n",
    "\n",
    "links = collect_article_links_from_fashion(max_pages=3)\n",
    "len(links), links[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4c91027-9b95-405b-8384-d46d20dd0bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_article(url: str) -> dict:\n",
    "    soup = get_soup(url)\n",
    "\n",
    "   \n",
    "    jsonld_blocks = soup.select('script[type=\"application/ld+json\"]')\n",
    "    for block in jsonld_blocks:\n",
    "        raw = block.get_text(strip=True)\n",
    "        if not raw:\n",
    "            continue\n",
    "        try:\n",
    "            data = json.loads(raw)\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "        candidates = data if isinstance(data, list) else [data]\n",
    "        for item in candidates:\n",
    "            if not isinstance(item, dict):\n",
    "                continue\n",
    "            if item.get(\"@type\") in [\"NewsArticle\", \"Article\", \"BlogPosting\"]:\n",
    "                title = item.get(\"headline\") or \"\"\n",
    "                date_published = item.get(\"datePublished\") or \"\"\n",
    "                body = item.get(\"articleBody\") or \"\"\n",
    "                img = \"\"\n",
    "                if isinstance(item.get(\"image\"), str):\n",
    "                    img = item[\"image\"]\n",
    "                elif isinstance(item.get(\"image\"), dict):\n",
    "                    img = item[\"image\"].get(\"url\", \"\") or \"\"\n",
    "                elif isinstance(item.get(\"image\"), list) and item[\"image\"]:\n",
    "                    img = item[\"image\"][0] if isinstance(item[\"image\"][0], str) else \"\"\n",
    "\n",
    "                author = \"\"\n",
    "                if isinstance(item.get(\"author\"), dict):\n",
    "                    author = item[\"author\"].get(\"name\", \"\") or \"\"\n",
    "                elif isinstance(item.get(\"author\"), list) and item[\"author\"]:\n",
    "                    if isinstance(item[\"author\"][0], dict):\n",
    "                        author = item[\"author\"][0].get(\"name\", \"\") or \"\"\n",
    "\n",
    "                if body.strip():\n",
    "                    return {\n",
    "                        \"url\": url,\n",
    "                        \"title\": clean_text(title),\n",
    "                        \"author\": clean_text(author),\n",
    "                        \"date_published\": clean_text(date_published),\n",
    "                        \"image\": clean_text(img),\n",
    "                        \"body\": clean_text(body),\n",
    "                        \"method\": \"json-ld\"\n",
    "                    }\n",
    "\n",
    "    \n",
    "    title = \"\"\n",
    "    h1 = soup.find(\"h1\")\n",
    "    if h1:\n",
    "        title = h1.get_text(\" \", strip=True)\n",
    "\n",
    "    \n",
    "    page_text = soup.get_text(\"\\n\", strip=True)\n",
    "    m = re.search(r\"\\bby\\s+([^\\n]+?)\\s+(\\d{4}\\.\\d{2}\\.\\d{2})\\b\", page_text, flags=re.IGNORECASE)\n",
    "    author = m.group(1).strip() if m else \"\"\n",
    "    date_published = m.group(2).strip() if m else \"\"\n",
    "\n",
    "    \n",
    "    image = \"\"\n",
    "    og = soup.select_one('meta[property=\"og:image\"][content]')\n",
    "    if og:\n",
    "        image = og.get(\"content\", \"\")\n",
    "\n",
    "   \n",
    "    article = soup.find(\"article\")\n",
    "    scope = article if article else soup\n",
    "\n",
    "    for tag in scope.select(\"script, style, noscript\"):\n",
    "        tag.decompose()\n",
    "\n",
    "    lines = [ln.strip() for ln in scope.get_text(\"\\n\", strip=True).split(\"\\n\")]\n",
    "    lines = [ln for ln in lines if len(ln) >= 20]\n",
    "\n",
    "   \n",
    "    cut_markers = [\"관련기사\", \"MOST POPULAR\", \"Credit\", \"Copyright\", \"ELLE\"]\n",
    "    cut_idx = None\n",
    "    for i, ln in enumerate(lines):\n",
    "        if any(marker in ln for marker in cut_markers):\n",
    "            cut_idx = i\n",
    "            break\n",
    "    if cut_idx is not None:\n",
    "        lines = lines[:cut_idx]\n",
    "\n",
    "    body = \"\\n\".join(lines)\n",
    "\n",
    "    return {\n",
    "        \"url\": url,\n",
    "        \"title\": clean_text(title),\n",
    "        \"author\": clean_text(author),\n",
    "        \"date_published\": clean_text(date_published),\n",
    "        \"image\": clean_text(image),\n",
    "        \"body\": clean_text(body),\n",
    "        \"method\": \"html-fallback\"\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9087ec4c-8cf3-46a9-874b-5e663fb95e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "수집된 article 링크 수: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:38<00:00,  1.29s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>date_published</th>\n",
       "      <th>image</th>\n",
       "      <th>body</th>\n",
       "      <th>method</th>\n",
       "      <th>body_preview</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.elle.co.kr/article/1878702</td>\n",
       "      <td>미니 스커트를 입으면</td>\n",
       "      <td>박기호</td>\n",
       "      <td>2025.03.18</td>\n",
       "      <td>https://www.elle.co.kr/resources/online/thumbn...</td>\n",
       "      <td>이 핫플 다음에 또 보고 싶다면? 찜하기! 시그너처 패턴을 프린트한 빅 포켓 미니스...</td>\n",
       "      <td>html-fallback</td>\n",
       "      <td>이 핫플 다음에 또 보고 싶다면? 찜하기! 시그너처 패턴을 프린트한 빅 포켓 미니스...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.elle.co.kr/article/1882445</td>\n",
       "      <td>스카프 이곳에 두르면 몇 배 더 예뻐 보입니다</td>\n",
       "      <td>강민지</td>\n",
       "      <td>2025.05.29</td>\n",
       "      <td>https://www.elle.co.kr/resources/online/thumbn...</td>\n",
       "      <td>스카프 이곳에 두르면 몇 배 더 예뻐 보입니다 스카프 이곳에 두르면 몇 배 더 예뻐...</td>\n",
       "      <td>html-fallback</td>\n",
       "      <td>스카프 이곳에 두르면 몇 배 더 예뻐 보입니다 스카프 이곳에 두르면 몇 배 더 예뻐...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.elle.co.kr/article/1884766</td>\n",
       "      <td>파리 패션피플은 지금 청바지를 죄다 이렇게 입어요</td>\n",
       "      <td>박지우</td>\n",
       "      <td>2025.07.15</td>\n",
       "      <td>https://www.elle.co.kr/resources/online/thumbn...</td>\n",
       "      <td>파리 패션피플은 지금 청바지를 죄다 이렇게 입어요 파리 패션피플은 지금 청바지를 죄...</td>\n",
       "      <td>html-fallback</td>\n",
       "      <td>파리 패션피플은 지금 청바지를 죄다 이렇게 입어요 파리 패션피플은 지금 청바지를 죄...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.elle.co.kr/article/1885541</td>\n",
       "      <td>뭐 하나 허투루 안 입는 로제의 바지 레슨3</td>\n",
       "      <td>강민지</td>\n",
       "      <td>2025.07.30</td>\n",
       "      <td>https://www.elle.co.kr/resources/online/thumbn...</td>\n",
       "      <td>뭐 하나 허투루 안 입는 로제의 바지 레슨3 뭐 하나 허투루 안 입는 로제의 바지 ...</td>\n",
       "      <td>html-fallback</td>\n",
       "      <td>뭐 하나 허투루 안 입는 로제의 바지 레슨3 뭐 하나 허투루 안 입는 로제의 바지 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.elle.co.kr/article/1886775</td>\n",
       "      <td>올가을 운동화보다 더 자주 신게 될 신발</td>\n",
       "      <td>강민지</td>\n",
       "      <td>2025.08.25</td>\n",
       "      <td>https://www.elle.co.kr/resources/online/thumbn...</td>\n",
       "      <td>올가을 운동화보다 더 자주 신게 될 신발 올가을 운동화보다 더 자주 신게 될 신발 ...</td>\n",
       "      <td>html-fallback</td>\n",
       "      <td>올가을 운동화보다 더 자주 신게 될 신발 올가을 운동화보다 더 자주 신게 될 신발 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      url                        title author  \\\n",
       "0  https://www.elle.co.kr/article/1878702                  미니 스커트를 입으면    박기호   \n",
       "1  https://www.elle.co.kr/article/1882445    스카프 이곳에 두르면 몇 배 더 예뻐 보입니다    강민지   \n",
       "2  https://www.elle.co.kr/article/1884766  파리 패션피플은 지금 청바지를 죄다 이렇게 입어요    박지우   \n",
       "3  https://www.elle.co.kr/article/1885541     뭐 하나 허투루 안 입는 로제의 바지 레슨3    강민지   \n",
       "4  https://www.elle.co.kr/article/1886775       올가을 운동화보다 더 자주 신게 될 신발    강민지   \n",
       "\n",
       "  date_published                                              image  \\\n",
       "0     2025.03.18  https://www.elle.co.kr/resources/online/thumbn...   \n",
       "1     2025.05.29  https://www.elle.co.kr/resources/online/thumbn...   \n",
       "2     2025.07.15  https://www.elle.co.kr/resources/online/thumbn...   \n",
       "3     2025.07.30  https://www.elle.co.kr/resources/online/thumbn...   \n",
       "4     2025.08.25  https://www.elle.co.kr/resources/online/thumbn...   \n",
       "\n",
       "                                                body         method  \\\n",
       "0  이 핫플 다음에 또 보고 싶다면? 찜하기! 시그너처 패턴을 프린트한 빅 포켓 미니스...  html-fallback   \n",
       "1  스카프 이곳에 두르면 몇 배 더 예뻐 보입니다 스카프 이곳에 두르면 몇 배 더 예뻐...  html-fallback   \n",
       "2  파리 패션피플은 지금 청바지를 죄다 이렇게 입어요 파리 패션피플은 지금 청바지를 죄...  html-fallback   \n",
       "3  뭐 하나 허투루 안 입는 로제의 바지 레슨3 뭐 하나 허투루 안 입는 로제의 바지 ...  html-fallback   \n",
       "4  올가을 운동화보다 더 자주 신게 될 신발 올가을 운동화보다 더 자주 신게 될 신발 ...  html-fallback   \n",
       "\n",
       "                                        body_preview  \n",
       "0  이 핫플 다음에 또 보고 싶다면? 찜하기! 시그너처 패턴을 프린트한 빅 포켓 미니스...  \n",
       "1  스카프 이곳에 두르면 몇 배 더 예뻐 보입니다 스카프 이곳에 두르면 몇 배 더 예뻐...  \n",
       "2  파리 패션피플은 지금 청바지를 죄다 이렇게 입어요 파리 패션피플은 지금 청바지를 죄...  \n",
       "3  뭐 하나 허투루 안 입는 로제의 바지 레슨3 뭐 하나 허투루 안 입는 로제의 바지 ...  \n",
       "4  올가을 운동화보다 더 자주 신게 될 신발 올가을 운동화보다 더 자주 신게 될 신발 ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "links = collect_article_links_from_fashion(max_pages=3)\n",
    "print(\"수집된 article 링크 수:\", len(links))\n",
    "\n",
    "\n",
    "rows = []\n",
    "for u in tqdm(links[:30]): \n",
    "    try:\n",
    "        rows.append(parse_article(u))\n",
    "        polite_sleep()\n",
    "    except Exception as e:\n",
    "        rows.append({\"url\": u, \"error\": str(e)})\n",
    "        polite_sleep()\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "df[\"body_preview\"] = df[\"body\"].astype(str).str.slice(0, 200)\n",
    "\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7b8585a-dba6-4b20-827d-c861fe2d15fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'elle_fashion_articles.csv'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_path = \"elle_fashion_articles.csv\"\n",
    "df.to_csv(out_path, index=False, encoding=\"utf-8-sig\")\n",
    "out_path\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pw312)",
   "language": "python",
   "name": "pw312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
